{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Симуляция секвенирования\n",
    "\n",
    "Первое задание заключается в том, чтобы написать симуляцию секвенирования ридов при помощи illumina. Для этого необходимо сгенерировать случайно строку длинной 50 000 символов, над алфавитом {A, T, G, C}. После этого случайно выбирать подстроки, длинна которых распределена нормально со средним 250 и среднеквадратическим отклонением 30, каждую такую подстроку \"секвенировать\".</br>\n",
    "Под словом \"секвенировать\" в данном случае имеется ввиду симуляция того процесса, который мы обсуждали на лекции. Вы считываете очередной символ подстроки, например, 100 раз, но в N случаях из 100 ошибаетесь и считываете любой нуклеотид, кроме правильного с одинаковой вероятностью. N принадлежит равномерному распределению от 0 до 75. По получившемуся набору вычисляете наибоее вероятный нуклеотид (тот, которого больше всего) и его качество прочтения, чтобы записать его в формате FASTQ.</br>\n",
    "При симуляции важно запоминать ID рида и для каждого ID позиции, в которых нуклеотид был считан неверно и какой должен быть на самом деле (для этого просто можно хранить 2 числа и помнить что у вас есть исходная строка, откуда берутся риды). Это понадобится для выполнения следующих заданий.</br>\n",
    "Всего ридов пусть будет 50К.</br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "nucleotides = ['A', 'T', 'G', 'C']\n",
    "\n",
    "sequence_string = ''.join(np.random.choice(nucleotides, 50000).tolist())\n",
    "read_mistakes = {'read_number': [], 'start_position_ID': [], 'mistake_position_ID': []}\n",
    "\n",
    "for i in range(1, 50001):\n",
    "    read_mistakes['read_number'].append(i)\n",
    "    read_len = int(np.random.normal(250, 30, 1)[0])\n",
    "    read_start = np.random.default_rng().integers(0, 50000 - read_len)\n",
    "    read_mistakes['start_position_ID'].append(read_start)\n",
    "    read_str = sequence_string[read_start:read_start+read_len]\n",
    "    mistakes_str = ''\n",
    "    mistakes_pos = []\n",
    "    for nucleotide_idx in range(read_len):\n",
    "        nucleotide = read_str[nucleotide_idx]\n",
    "        n = np.random.default_rng().integers(1, 75)\n",
    "        mistakes = np.random.choice([nuc for nuc in nucleotides if nuc != nucleotide], n)\n",
    "        vals, counts = np.unique(mistakes, return_counts=True)\n",
    "        if max(counts) > 100-n:\n",
    "            read_str = read_str[:nucleotide_idx] + vals[np.argmax(counts)] + read_str[nucleotide_idx+1:]\n",
    "            q = int(-10*np.log10((100-max(counts))/100))\n",
    "            mistakes_pos.append(nucleotide_idx)\n",
    "        else:\n",
    "            q = int(-10*np.log10(n/100))\n",
    "        mistakes_str += chr(q + 33)\n",
    "    read_mistakes['mistake_position_ID'].append(mistakes_pos)\n",
    "    mistakes_str += '\\n'    \n",
    "    with open(f\"reads.fasta\", \"a\") as file:\n",
    "        file.write(f'@READ_SEQ_{i}\\n')\n",
    "        file.write(read_str + '\\n')\n",
    "        file.write('+\\n')\n",
    "        file.write(mistakes_str)\n",
    "\n",
    "pd.DataFrame.from_dict(read_mistakes).to_csv('read_mistakes.csv', index=False)\n",
    "\n",
    "with open(\"sequense.fasta\", \"w\") as file:\n",
    "    file.write('@MAIN_SEQ_0\\n')\n",
    "    file.write(sequence_string)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Удаление ошибок (Trimmomatic) \n",
    "Получившиеся риды обработайте Trimmomatic со стандартными параметрами с лекции. Пользуясь тем, что вы знаете, для каждого рида ground truth, посчитайте, в скольких случаях Trimmomatic удалил нуклеотиды, которые были считаны верно, а в скольких действительно удалил ошибочные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TrimmomaticSE: Started with arguments:\n",
      " -phred33 reads.fasta reads_trim.fasta ILLUMINACLIP:TruSeq3-SE.fa:2:30:10:2:True LEADING:3 TRAILING:3 MINLEN:36\n",
      "Automatically using 4 threads\n",
      "Using Long Clipping Sequence: 'AGATCGGAAGAGCGTCGTGTAGGGAAAGAGTGTA'\n",
      "Using Long Clipping Sequence: 'AGATCGGAAGAGCACACGTCTGAACTCCAGTCAC'\n",
      "ILLUMINACLIP: Using 0 prefix pairs, 2 forward/reverse sequences, 0 forward only sequences, 0 reverse only sequences\n",
      "Input Reads: 50000 Surviving: 50000 (100.00%) Dropped: 0 (0.00%)\n",
      "TrimmomaticSE: Completed successfully\n"
     ]
    }
   ],
   "source": [
    "! trimmomatic SE -phred33 reads.fasta reads_trim.fasta ILLUMINACLIP:TruSeq3-SE.fa:2:30:10:2:True LEADING:3 TRAILING:3 MINLEN:36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_mistakes = pd.read_csv('/home/pk/Desktop/BOTAY/BioinformaticsCourse2024PK/homework/2_1/read_mistakes.csv')\n",
    "\n",
    "with open(\"reads_trim.fasta\", \"r\") as file1:\n",
    "    lines_trimm = file1.readlines()\n",
    "\n",
    "with open(\"reads.fasta\", \"r\") as file2:\n",
    "    lines = file2.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_del = 0\n",
    "false_del = 0\n",
    "id = 1\n",
    "\n",
    "for i in range(0, len(lines_trimm), 4):\n",
    "    try:\n",
    "        mistakes_idxs = set(map(int, df_mistakes.loc[df_mistakes['read_number'] == id]['mistake_position_ID'].iloc[0][1:-1].split(', ')))\n",
    "    except:\n",
    "        mistakes_idxs = []  # если пустой массив\n",
    "    read = lines[i+1]\n",
    "    read_trimm = lines_trimm[i+1] + '$'\n",
    "    for elem_idx in range(len(read)):\n",
    "        if read[elem_idx] != read_trimm[elem_idx]:\n",
    "            read_trimm = read_trimm[:elem_idx] + '-' + read_trimm[elem_idx:]\n",
    "            if elem_idx in mistakes_idxs:\n",
    "                true_del += 1\n",
    "            else:\n",
    "                false_del += 1\n",
    "    id += 1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Верные удаления: 3942\n",
      "Ошибочные удаления: 43724\n"
     ]
    }
   ],
   "source": [
    "print('Верные удаления:', true_del)\n",
    "print('Ошибочные удаления:', false_del)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Коррекция ошибок \n",
    "\n",
    "Получившиеся риды обработайте одним(любым) из инструментов, которые использованы и проанализированны в этой [статье](https://genomebiology.biomedcentral.com/articles/10.1186/s13059-020-01988-3). Посчитайте TP, FP, TN, FN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для исправления ошибок я решил использовать метод [Lighter](https://github.com/mourisl/Lighter). Размер k-мера был выбран равным 20 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels:\n",
      " - bioconda\n",
      " - defaults\n",
      " - conda-forge\n",
      "Platform: linux-64\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! conda install lighter --channel bioconda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-06-02 11:57:37] =============Start====================\n",
      "[2024-06-02 11:57:37] Scanning the input files to infer alpha(sampling rate)\n",
      "[2024-06-02 11:57:37] Average coverage is 249.634 and alpha is 0.028\n",
      "[2024-06-02 11:57:37] Bad quality threshold is \"!\"\n",
      "[2024-06-02 11:57:39] Finish sampling kmers\n",
      "[2024-06-02 11:57:39] Bloom filter A's false positive rate: 0.335902\n",
      "[2024-06-02 11:57:39] The error rate is high. Lighter adjusts -maxcor to 5 and bad quality threshold to \"\"\".\n",
      "[2024-06-02 11:57:40] Finish storing trusted kmers\n",
      "[2024-06-02 11:57:40] Finish error correction\n",
      "Processed 50000 reads:\n",
      "\t74 are error-free\n",
      "\tCorrected 343435 bases(6.878881 corrections for reads with errors)\n",
      "\tTrimmed 0 reads with average trimmed bases 0.000000\n",
      "\tDiscard 0 reads\n"
     ]
    }
   ],
   "source": [
    "! lighter -r reads.fasta -K 20 50000 -t 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_mistakes = pd.read_csv('/home/pk/Desktop/BOTAY/BioinformaticsCourse2024PK/homework/2_1/read_mistakes.csv')\n",
    "\n",
    "with open(\"reads.cor.fq\", \"r\") as file1:\n",
    "    lines_cor = file1.readlines()\n",
    "\n",
    "with open(\"reads.fasta\", \"r\") as file2:\n",
    "    lines = file2.readlines()\n",
    "\n",
    "with open(\"sequense.fasta\", \"r\") as file3:\n",
    "    sequence = file3.readlines()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP = 343432\n",
      "FP = 3\n",
      "TN = 12150054\n",
      "FN = 38217\n"
     ]
    }
   ],
   "source": [
    "TP = 0  # ошибочные нуклеотиды, которые были исправлены\n",
    "TN = 0  # правильные нуклеотилы, которые были нетронуты\n",
    "FP = 0  # правильные нуклеодиты, которые были исправлены\n",
    "FN = 0  # ошибочные нуклеотиды, которые не были исправлены\n",
    "id = 1\n",
    "\n",
    "for i in range(0, len(lines_cor), 4):\n",
    "    start_position = int(df_mistakes.loc[df_mistakes['read_number'] == id]['start_position_ID'].iloc[0])\n",
    "    try:\n",
    "        mistakes_idxs = set(map(int, df_mistakes.loc[df_mistakes['read_number'] == id]['mistake_position_ID'].iloc[0][1:-1].split(', ')))\n",
    "    except:\n",
    "        mistakes_idxs = []\n",
    "    read = lines[i+1]\n",
    "    read_cor = lines_cor[i+1]\n",
    "    for elem_idx in range(len(read)):\n",
    "        if read[elem_idx] != read_cor[elem_idx]:\n",
    "            if elem_idx in mistakes_idxs and read_cor[elem_idx] == sequence[start_position+elem_idx]:\n",
    "                TP += 1\n",
    "            elif elem_idx in mistakes_idxs and read_cor[elem_idx] != sequence[start_position+elem_idx]:\n",
    "                FN += 1\n",
    "            elif elem_idx not in mistakes_idxs:\n",
    "                FP += 1\n",
    "        else:\n",
    "            if elem_idx in mistakes_idxs:\n",
    "                FN += 1\n",
    "            else:\n",
    "                TN += 1\n",
    "    id += 1\n",
    "\n",
    "print('TP =', TP)\n",
    "print('FP =', FP)\n",
    "print('TN =', TN)\n",
    "print('FN =', FN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сделайте какой-то вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучше использовать алгоритмы по исправлению ридов с ошибками, так как они позволяют более точно и без удаления нуклеотидов (и, следовательно, потери информации) улучшать качество получаемых в ходе секвенирования последовательностей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
